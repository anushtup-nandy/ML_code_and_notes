from: [[Ch-2 Statistical learning]] 
to: [[2.1.2 HOW DO WE ESTIMATE f]]
### 2.1.1WHY ESTIMATE f?
2 reasons: prediction and inference

#### 2.1.1.1PREDICTION:
a set of inputs X are readily available, but the output Y cannot be easily obtained. We try to *predict Y using:*
$$\hat Y = \hat f(X)----(2.2)$$
ˆf represents our estimate for f, and Yˆ represents the resulting prediction.

The accuracy of Yˆ as a prediction for Y depends on two quantities, which we will call the reducible error and the irreducible error. In general, ˆf will not be a perfect estimate for f, and this inaccuracy will introduce some error. This error is reducible because we can potentially improve the accuracy of ˆf by using the most appropriate statistical learning technique to estimate f.
The variability associated with $\epsilon$ also affects the accuracy of our predictions. This is known as the irreducible error
$$
E(Y-\hat{Y})=[f(X)-\hat{f}(X)]^{2}+Var(\epsilon)----(2.3)
$$
where:
1. first term is the reducible error
2. Var(e) is the irreducible error.

#### 2.1.1.2INFERENCE:
understanding the association between Y and X1, . . . , Xp

Answering the following questions is important:
- Which predictors are associated with the response?
- What is the relationship between the response and each predictor
- Can the relationship between Y and each predictor be adequately summarized using a linear equation, or is the relation more compliccated?