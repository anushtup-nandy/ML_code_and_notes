2022/08/10  (10:32)
from: [[5.1.2 LEAVE-ONE-OUT CROSS-VALIDATION]]
to: [[5.1.4 BIAS-VARIANCE TRADE-OFF FOR K-FOLD CROSS VALIDATION]]

### 5.1.3 K-FOLD CROSS-VALIDATION:
Alternative to LOOCV. This apprach involves randomly dividing the set of observations into k groups or folds of appraoximately the same size.

>The first fold is treated as the validation set and the method is fit on the rest (k-1)

The MSE is then computed on the observations in the held-out fold. This procedure is repeated k-times (results in k estimates of the test error)
$$
CV_k=\frac{1}{k}\sum\limits_{i=1}^kMSE_i----(5.3)
$$
>[!note]
>LOOCV is a special case of K-fold cross validation where k=n

K-fold cross validation is usually done with k=5 or 10 rather than n. This gives it a computational advantage (faster and less taxing on the system).
![[Pasted image 20220810103912.png]]

When we perform cross-validation, our goal might be to determine how well a given statistical learning procedure can be expected to perform on independent data; in this case, the actual estimate of the test MSE is of interest. But at other times we are interested only in the location of the minimum point in the estimated test MSE curve.

We find in Figure 5.6 that despite the fact that they sometimes underestimate the true test MSE, all of the CV curves come close to identifying the correct level of flexibilityâ€”that is, the flexibility level corresponding to the smallest test MSE.

To identify the method that results in the lowest MSE, we tend to look at the lowest point in the MSE vs flexibility curve.

