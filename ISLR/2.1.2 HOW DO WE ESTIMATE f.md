from: [[2.1.1WHY ESTIMATE f]]
to:[[2.1.3 TRADE-OFF BETWEEN PREDICTION ACC. AD INTERPRETABILITY]]
### 2.1.2 HOW DO WE ESTIMATE f?
2 methods:
- Parametric
- non-parametric

we want to find a function ˆf such that $Y ≈ \hat{f}(X)$ for any observation (X, Y ). Broadly speaking, most statistical learning methods for this task can be characterized as either parametric or non-parametric

#### 2.1.2.1 PARAMETRIC:
2 step model based approach:
a. ![[Pasted image 20220712152828.png]]
we make an assumption about the functional form, or shape, of f. For example, one very simple assumption is that f is linear in . one only needs to estimate the p + 1 coefficients β0, β1, . . . , βp.

b.After a model has been selected, we need a procedure that uses the training data to fit or train the model.
![[Pasted image 20220712152928.png]]
The most common approach to fitting the model (2.4) is referred to as (ordinary) least squares.
![[Pasted image 20220712153051.png|500]]
*The potential disadvantage of a parametric approach is that the model we choose will usually not match the true unknown form of f.*
We can try to address this problem by choosing **flexible models** that can fit many different possible functional forms flexible for f. But, this may lead to **OVERFITTING**. #overfitting 

#### 2.1.2.2 NON-PARAMETRIC:
Non-parametric methods do not make explicit assumptions about the functional form of f. Instead they seek an estimate of f that gets as close to the data points as possible without being too rough or wiggly.

Non-parametric approaches do suffer from a **major disadvantage: since they do not reduce the problem of estimating f to a small number of parameters, a very large number of observations** (far more than is typically needed for a parametric approach) is required in order to obtain an accurate estimate for f