2022/07/18  (10:16)
from: [[Ch-4 Classification]]
to: [[4.1.2 ESTIMATING THE REGRESSION COEFFICIENTS]]

### 4.1.1 THE LOGISTIC MODEL:
Here, we are concerned with modelling the relationship between $p(X)=Pr(Y=1|X)$ and $X$.
The linear regression model for the same can be: 
$$
p(X)=\beta_{0} + \beta_{1}X----(4.1)
$$
with this we'll get a straight line graph (model) which is not really correct here. 
What happens is: 
>for balances close to zero we predict a negative probability of default; if we were to predict for very large balances, we would get values bigger than 1

Hence, we'll make use of the Logistic function:
$$
p(X)=\frac{e^{\beta_{0}+ \beta_1X}}{1+e^{\beta_{0}+ \beta_1X}}----(4.2)
$$

This function gives the results of p(X) in 0-1!.
***To fit this model we use something called: maximum likelihood***
This curve always gives a *s-shaped plot.*
![[Pasted image 20220713130312.png]]
Here, we can manipulate (4.2) to get something known as **ODDS**
$$
\frac{p(X)}{1-p(X)}=e^{\beta_{0}+\beta_1X}----(4.3)
$$
The quantity $p(X)/(1-p(X))$ is called the odds, and can take on any value between 0 and ∞. Values of the odds close to 0 and ∞ indicate very low and very high probabilities of default, respectively
Another thing to note:
==**LOGIT**:==
$$
log(\frac{p(X)}{1-p(X)})=\beta_{0}+\beta_{1X}---- (4.4)
$$
Logistic regression has a **logit** linear in X. (here X is balance)

In a logistic regression model, increasing X by one unit changes the log odds by β1 (4.4). Equivalently, it multiplies the odds by e β1 (4.3).
The amount that p(X) changes due to a one-unit change in X depends on the current value of X. But regardless of the value of X, if β1 is positive then increasing X will be associated with increasing p(X), and if β1 is negative then increasing X will be associated with decreasing p(X)